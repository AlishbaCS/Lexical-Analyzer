# ğŸ” Lexical Analyzer â€“ Token and Symbol Table Generator

## ğŸ“„ Overview

This project implements a **Lexical Analyzer** (scanner) for a simplified programming language using Python. It processes source code, identifies valid tokens, categorizes them (keywords, identifiers, literals, etc.), and writes the results to:

- `Token.txt` â€“ all recognized tokens  
- `Error.txt` â€“ unrecognized or invalid tokens  
- `SymbolTable.txt` â€“ categorized symbol table

It supports C/C++-like syntax including keywords, identifiers, operators, literals, comments, and more.

---

## ğŸš€ How It Works

1. Reads code from `sourcecode.txt`
2. Classifies each token using rules
3. Writes tokens and errors to separate files
4. Generates a symbol table of categorized tokens

---

## ğŸ“š Libraries Used

Only built-in Python libraries are used:

- File I/O  
- Custom classes (`Node`, `LinkedList`) for token handling

---

## ğŸ§  Token Categories Handled

- **Keywords:** `int`, `float`, `return`, `for`, `if`, etc.  
- **Operators:** `=`, `+`, `*`, etc.  
- **Punctuation/Separators:** `(`, `)`, `{`, `}`, `;`  
- **Identifiers:** variable/function names  
- **Literals:** string, boolean, numeric constants  
- **Comments:** `//`, `/* */`, `#`  
- **Invalid Tokens:** unrecognized or malformed inputs

---

## ğŸ”§ How to Use

1. **Prepare the input file:**
   - Write your sample code in `sourcecode.txt`

2. **Run the analyzer:**
   ```bash
   python code.py

### ğŸ“¤ Output Files Generated

- `Token.txt` â€“ contains all valid tokens with their types  
- `Error.txt` â€“ lists any lexical errors or invalid tokens  
- `SymbolTable.txt` â€“ a categorized symbol table (keywords, identifiers, literals, etc.)

---

### ğŸ“ File Structure

.
â”œâ”€â”€ code.py # Main lexical analyzer

â”œâ”€â”€ sourcecode.txt # Input code to scan

â”œâ”€â”€ Token.txt # Output: list of tokens

â”œâ”€â”€ Error.txt # Output: list of invalid tokens

â”œâ”€â”€ SymbolTable.txt # Output: organized symbol table

â””â”€â”€ README.md # Project documentation


---

### âœ… Example Output

**Input (`sourcecode.txt`):**
```c
int main() {
    int x = 5;
    // This is a comment
    printf("Hello World");
}
```

Output (Token.txt):
```
(keyword, int)
(identifier, main)
(punctuation, ()
(punctuation, ))
(punctuation, {)
(keyword, int)
(identifier, x)
(operator, =)
(constant, 5)
(punctuation, ;)
(comment, //)
(identifier, printf)
(literal, "Hello World")
(punctuation, ;)
(punctuation, })

```
## Notes

Handles single-line (//), multi-line (/* */), and hash (#) comments


Supports simple operators and literals


Includes basic error handling for invalid tokens


Uses a LinkedList to store and process token streams efficiently

## Acknowledgments

Built as part of a compiler or language processing module. Inspired by how real-world lexical analyzers tokenize and categorize code for further compilation.
